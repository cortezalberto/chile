# WebSocket Gateway: Arquitectura Modular y Funcionamiento Interno

**Versión 3.0 - Febrero 2026**

## Introducción

El WebSocket Gateway constituye el sistema nervioso central de comunicación en tiempo real dentro del ecosistema Integrador. Este servicio, ejecutándose en el puerto 8001, desempeña un rol fundamental como intermediario entre los eventos de dominio generados por la API REST y los múltiples clientes conectados que requieren notificaciones instantáneas. A diferencia del modelo tradicional de polling, donde los clientes consultan repetidamente al servidor en busca de actualizaciones, el Gateway mantiene conexiones bidireccionales persistentes que permiten la transmisión inmediata de eventos sin latencia perceptible para el usuario final.

La arquitectura del Gateway fue diseñada desde sus cimientos para soportar operaciones de alta concurrencia en entornos de restauración exigentes. Con capacidad para manejar simultáneamente entre cuatrocientas y mil conexiones WebSocket, el sistema implementa patrones avanzados de gestión de recursos que incluyen locks fragmentados organizados por sucursal y usuario, un worker pool dedicado para broadcasting paralelo con diez workers, y pools de conexiones Redis optimizados para diferentes patrones de uso. Esta infraestructura robusta permite que un restaurante en hora pico pueda operar con docenas de mozos activos, múltiples terminales de cocina y cientos de comensales consultando el estado de sus pedidos, todos recibiendo actualizaciones en tiempo real sin degradación del servicio.

El proyecto experimentó una refactorización arquitectónica significativa, identificada internamente como ARCH-MODULAR, que transformó archivos monolíticos de casi mil líneas de código en orquestadores delgados que delegan responsabilidades específicas a módulos especializados. El connection manager se redujo de novecientas ochenta y siete líneas a aproximadamente cuatrocientas sesenta y tres, mientras que el redis subscriber pasó de seiscientas sesenta y seis líneas a cerca de trescientas veintiséis. Esta transformación no solo mejoró dramáticamente la mantenibilidad del código base sino que también habilitó testing unitario granular de cada componente y permitió la evolución independiente de subsistemas sin afectar otras partes del Gateway.

---

## Capítulo 1: Topología del Proyecto y Organización de Módulos

El WebSocket Gateway reside en la carpeta ws_gateway ubicada en la raíz del proyecto Integrador. Su organización interna refleja una arquitectura de componentes donde cada módulo posee una responsabilidad única y claramente definida, siguiendo el principio de responsabilidad única que constituye la S en los principios SOLID.

El archivo main.py representa el punto de entrada de la aplicación FastAPI con aproximadamente doscientas ochenta líneas de código. Este módulo configura la aplicación, define el lifespan manager que orquesta el ciclo de vida completo del servicio, y registra los endpoints WebSocket junto con los endpoints de salud y métricas. Aquí se inicializan los workers de broadcasting, se establecen las suscripciones a Redis, se configuran las tareas de mantenimiento periódico como la limpieza de conexiones inactivas, y se define el consumidor de Redis Streams para eventos críticos que requieren entrega garantizada.

Los dos orquestadores principales, connection_manager.py y redis_subscriber.py, fueron refactorizados desde implementaciones monolíticas a coordinadores delgados que actúan como fachadas componiendo módulos especializados mediante inyección de dependencias. El connection manager ahora coordina cuatro módulos extraídos: ConnectionLifecycle para la aceptación y desconexión de clientes, ConnectionBroadcaster para envío paralelo mediante worker pools, ConnectionCleanup para eliminación de conexiones muertas o inactivas, y ConnectionStats para agregación de estadísticas de rendimiento. De manera análoga, el redis subscriber coordina módulos para validación de eventos, tracking de eventos perdidos, y procesamiento por lotes.

El directorio core contiene los módulos extraídos de los orquestadores originales, organizados por dominio funcional. El subdirectorio connection agrupa cuatro módulos esenciales. El archivo lifecycle.py maneja la aceptación y desconexión de clientes WebSocket, implementando la verificación de límites de conexión, la validación de parámetros, y el registro en índices. El archivo broadcaster.py implementa el envío paralelo mediante worker pools con diez workers que procesan envíos concurrentemente, incluyendo la estrategia híbrida que selecciona automáticamente entre modo legacy para audiencias pequeñas y modo worker pool para broadcasts masivos. El archivo cleanup.py gestiona la identificación y eliminación de conexiones muertas o stale mediante el patrón de dos fases que evita errores de modificación de diccionarios durante iteración. El archivo stats.py agrega estadísticas de rendimiento incluyendo conteos de conexiones, broadcasts y eventos.

El subdirectorio subscriber dentro de core contiene módulos para el procesamiento de eventos Redis. El archivo drop_tracker.py monitorea y genera alertas cuando la tasa de eventos perdidos supera umbrales configurados, implementando una ventana deslizante de observación con cooldown entre alertas para evitar saturación del sistema de logging. El archivo validator.py valida esquemas de eventos entrantes verificando la presencia de campos requeridos como type, tenant_id y branch_id, y que el tipo de evento sea uno de los tipos conocidos y válidos. El archivo processor.py procesa lotes de eventos eficientemente, desacoplando la recepción de Redis del envío a conexiones WebSocket para mantener baja latencia.

El directorio components organiza funcionalidad transversal por dominio de responsabilidad, proporcionando una capa de abstracción adicional sobre los módulos core. Esta separación refleja dos niveles de abstracción complementarios: mientras core contiene los módulos extraídos directamente de los orquestadores monolíticos originales conservando su lógica fundamental, components organiza funcionalidad transversal facilitando la composición y reutilización de comportamientos comunes.

---

## Capítulo 2: El Punto de Entrada y Gestión del Ciclo de Vida

El archivo main.py configura la aplicación FastAPI y orquesta el ciclo de vida completo del Gateway mediante una función de lifespan asíncrona decorada con el context manager de asynccontextmanager. Esta función constituye el corazón de la orquestación del servicio, iniciando y deteniendo múltiples subsistemas de forma coordinada y ordenada.

Durante la fase de startup, el sistema inicializa cinco componentes críticos que operarán en paralelo durante la vida del servicio. Primero, se inicializa el broadcaster del connection manager llamando a manager.broadcaster.initialize(), lo que arranca el worker pool con diez workers que procesan envíos de mensajes concurrentemente mediante una cola asíncrona con capacidad máxima de cinco mil tareas pendientes, proporcionando backpressure cuando el sistema experimenta picos de carga. Segundo, se crea una instancia singleton del EventRouter mediante init_event_router() que centraliza la validación y enrutamiento de eventos, evitando la creación de múltiples instancias que podrían causar inconsistencias o condiciones de carrera en el routing.

Tercero, se inicia la tarea del suscriptor Redis Pub/Sub creando una coroutine que ejecuta subscriber.start() como background task. Esta tarea escucha eventos en canales de sucursal, sector y sesión mediante suscripciones por patrón que permiten capturar dinámicamente todos los canales relevantes sin conocerlos de antemano. Cuarto, se lanza el consumidor de Redis Streams para eventos críticos que requieren entrega garantizada, complementando el sistema Pub/Sub con semánticas de at-least-once delivery. Quinto, se activa la tarea de limpieza de heartbeat mediante create_task(heartbeat_cleanup_task()) que ejecuta periódicamente cada treinta segundos para remover conexiones que han permanecido inactivas por más del timeout configurado.

La fase de shutdown procede de manera ordenada y segura para evitar pérdida de datos o corrupción de estado. Primero se cancelan las tareas de suscripción y consumo de eventos verificando que existan antes de llamar cancel() y esperando su finalización con suppress de CancelledError, asegurando que no se procesen eventos nuevos durante el cierre. Luego se detiene el worker pool de broadcasting llamando a manager.broadcaster.shutdown() con un timeout de cinco segundos, permitiendo que los envíos en progreso finalicen graciosamente antes de forzar la terminación de workers que no respondan. A continuación se espera la finalización de cualquier operación de limpieza de locks pendiente. Finalmente se liberan los recursos del repositorio de sectores mediante cleanup_sector_repository() y se cierran los pools de conexiones Redis para liberar todos los recursos del sistema.

El Gateway expone diferentes endpoints WebSocket diferenciados por rol y método de autenticación, cada uno manejado por una clase de endpoint especializada que hereda de las clases base definidas en components/endpoints. El endpoint /ws/waiter acepta tokens JWT y permite conexiones de usuarios con roles WAITER, MANAGER o ADMIN, entregando notificaciones filtradas por los sectores asignados al mozo según su configuración del día actual. El endpoint /ws/kitchen también utiliza autenticación JWT pero está destinado a personal con roles KITCHEN, MANAGER o ADMIN, recibiendo únicamente las comandas que han sido enviadas a cocina y requieren preparación. El endpoint /ws/admin proporciona visibilidad completa de sucursal para usuarios MANAGER o ADMIN mediante autenticación JWT, recibiendo todos los eventos de la sucursal sin filtrado. El endpoint /ws/diner utiliza table tokens HMAC en lugar de JWT, permitiendo que los comensales reciban actualizaciones sobre el estado de sus pedidos personales sin necesidad de cuentas de usuario en el sistema.

Adicionalmente, el Gateway expone tres endpoints de observabilidad esenciales para el monitoreo operacional. El endpoint /ws/health responde a solicitudes GET con una verificación básica de disponibilidad del servicio retornando status healthy. El endpoint /ws/health/detailed ofrece información extendida ejecutando verificaciones asíncronas de Redis, reportando el estado de los pools de conexión, estadísticas de conexiones activas desglosadas por tipo, y el estado del circuit breaker. El endpoint /ws/metrics expone métricas en formato Prometheus para integración con sistemas de monitoreo y alerting, formateando los contadores del MetricsCollector según la especificación de Prometheus con líneas HELP y TYPE.

---

## Capítulo 3: El Connection Manager como Orquestador Central

El ConnectionManager representa la fachada principal para todas las operaciones relacionadas con conexiones WebSocket, residiendo en el archivo connection_manager.py con aproximadamente cuatrocientas sesenta y tres líneas de código tras la refactorización ARCH-MODULAR-08. Esta clase actúa como punto de entrada unificado que coordina múltiples subsistemas especializados, proporcionando una interfaz coherente mientras delega la complejidad a módulos internos que pueden ser testeados y mantenidos independientemente.

El constructor del ConnectionManager inicializa los componentes core necesarios mediante inyección de dependencias a través de la clase ConnectionManagerDependencies definida en components/core/dependencies.py. Esta clase contenedora agrupa todas las dependencias como singletons que pueden ser reemplazados durante testing. El LockManager proporciona coordinación de concurrencia mediante locks fragmentados por sucursal y usuario. El MetricsCollector centraliza estadísticas con operaciones thread-safe para contextos tanto async como sync. El HeartbeatTracker detecta conexiones inactivas manteniendo timestamps de última actividad. El WebSocketRateLimiter previene abuso limitando mensajes por conexión. El ConnectionIndex proporciona búsqueda rápida mediante múltiples índices.

La verdadera potencia del diseño radica en la composición de módulos especializados del directorio core/connection. El objeto _lifecycle de tipo ConnectionLifecycle encapsula toda la lógica de registro y desregistro de conexiones, incluyendo verificación de límites, validación de parámetros, aceptación del WebSocket con timeout, y actualización de índices. El objeto _cleanup de tipo ConnectionCleanup maneja la identificación y eliminación de conexiones muertas o stale mediante el patrón de dos fases. El objeto _broadcaster de tipo ConnectionBroadcaster implementa el envío paralelo de mensajes mediante worker pools con estrategia híbrida de selección. El objeto _stats de tipo ConnectionStats agrega y expone estadísticas de rendimiento consultando los índices y el metrics collector.

Esta composición permite que cada aspecto de la gestión de conexiones sea probado, mantenido y evolucionado independientemente sin afectar otros componentes. Los métodos públicos del manager simplemente delegan al módulo apropiado con mínima lógica de coordinación: una llamada a connect() invoca internamente _lifecycle.connect(), mientras que send_to_branch() delega a _broadcaster.send_to_branch(). Este patrón de delegación mantiene el código del manager legible y facilita la sustitución de implementaciones durante testing mediante el contenedor de dependencias.

El manager también expone propiedades de conveniencia que proporcionan acceso a submódulos para código que necesita funcionalidad específica. La propiedad broadcaster retorna el objeto _broadcaster permitiendo acceso directo a métodos de envío especializados. La propiedad lifecycle retorna el objeto _lifecycle para operaciones de registro avanzadas. Estas propiedades mantienen la encapsulación mientras permiten acceso controlado cuando es necesario.

---

## Capítulo 4: Sistema de Índices para Búsqueda de Conexiones

El sistema mantiene múltiples índices para localizar conexiones en tiempo constante O(1) según diferentes criterios de búsqueda, implementados en la clase ConnectionIndex ubicada en components/connection/index.py. Esta clase encapsula las estructuras de datos junto con las operaciones de registro, búsqueda y eliminación, actuando como un value object que representa el estado actual de todas las conexiones del sistema.

Los índices primarios organizan conexiones por atributo clave utilizando diccionarios que mapean identificadores a conjuntos de WebSockets. El diccionario by_user mapea identificadores de usuario a conjuntos de sus conexiones activas, permitiendo enviar mensajes a todas las sesiones de un usuario específico cuando este tiene múltiples dispositivos conectados. El diccionario by_branch agrupa conexiones por sucursal, fundamental para broadcasts de eventos de negocio que deben llegar a todo el personal de una ubicación específica. El diccionario by_sector mantiene conexiones de mozos organizadas por sector asignado, habilitando notificaciones dirigidas solo al personal responsable de ciertas mesas cuando un evento solo es relevante para el área específica del restaurante. El diccionario by_session agrupa conexiones de comensales por sesión de mesa, permitiendo que todos los participantes de una mesa reciban actualizaciones de su pedido compartido en tiempo real.

Los índices por rol proporcionan acceso rápido a conexiones con permisos específicos que requieren tratamiento diferenciado. El diccionario admins_by_branch contiene conexiones de administradores y managers por sucursal, utilizado para eventos que requieren visibilidad de gestión como confirmaciones de pedidos o alertas operativas. El diccionario kitchen_by_branch agrupa personal de cocina por sucursal, destinatarios de comandas y actualizaciones de preparación que solo son relevantes para el área de producción.

Los mappings inversos permiten obtener información sobre una conexión específica sin iterar sobre todos los índices, operación que sería costosa en un sistema con cientos de conexiones. El diccionario _ws_to_user mapea cada WebSocket a su user_id asociado, permitiendo identificar al propietario de una conexión durante operaciones de limpieza. El diccionario _ws_to_tenant mapea cada conexión a su tenant_id para filtrado multi-tenant que garantiza aislamiento entre restaurantes. El diccionario _ws_to_branches almacena los branch_ids a los que cada conexión tiene acceso, utilizado durante verificaciones de autorización.

El diseño de índices múltiples permite broadcasts selectivos sin necesidad de iterar sobre todas las conexiones activas del sistema, lo cual degradaría el rendimiento bajo carga. Cuando un evento debe llegar únicamente a los mozos del sector Terraza, el sistema consulta directamente by_sector con el identificador del sector y obtiene inmediatamente el conjunto exacto de conexiones destinatarias, sin examinar las cientos de otras conexiones que podrían estar activas simultáneamente en otros sectores, sucursales o roles.

---

## Capítulo 5: Locks Fragmentados y Prevención de Deadlocks

Para manejar alta concurrencia sin contención excesiva que degradaría el rendimiento, el Gateway implementa un sistema de locks fragmentados coordinado por el LockManager ubicado en components/connection/locks.py. Esta estrategia divide la sincronización en múltiples locks independientes, permitiendo que operaciones no relacionadas procedan en paralelo sin bloquearse mutuamente.

El sistema define diferentes tipos de locks según su alcance y el recurso que protegen. El connection_counter_lock protege el contador global de conexiones activas como un recurso compartido crítico, asegurando que los límites de capacidad se respeten atómicamente cuando múltiples conexiones intentan registrarse simultáneamente. Los branch_locks proporcionan un lock por cada sucursal almacenados en un defaultdict, de modo que operaciones en sucursales diferentes no compiten por el mismo recurso y pueden ejecutarse en paralelo completo. Los user_locks ofrecen un lock por cada usuario, permitiendo que conexiones de diferentes usuarios se manejen concurrentemente sin interferencia.

Locks adicionales protegen estructuras de datos específicas que cruzan los límites de usuario o sucursal. El sector_lock protege el índice by_sector durante actualizaciones que afectan múltiples sectores. El session_lock protege el índice by_session para conexiones de comensales. El dead_connections_lock protege el conjunto de conexiones marcadas para limpieza diferida.

Cuando un mozo se conecta a la sucursal número cinco, el sistema solo adquiere el lock de esa sucursal específica mediante get_branch_lock(5). Esto permite que conexiones simultáneas a otras sucursales procedan sin bloqueo alguno. Esta estrategia de fragmentación reduce la contención en aproximadamente un noventa por ciento comparado con un lock global único, mejora crítica para sostener cientos de conexiones concurrentes durante las horas pico de operación.

El orden de adquisición de locks está estrictamente definido para prevenir deadlocks, siguiendo una jerarquía clara documentada en el código. Primero siempre se adquiere el connection_counter_lock como lock global de máxima prioridad que controla el recurso más fundamental. Luego los user_locks en orden ascendente de user_id cuando se necesitan múltiples locks de usuario simultáneamente. Después los branch_locks también en orden ascendente de branch_id para mantener consistencia. Finalmente los locks secundarios sector_lock, session_lock y dead_connections_lock que protegen estructuras auxiliares.

Para garantizar el cumplimiento del orden de locks, el módulo lock_sequence.py implementa un context manager especializado que valida la secuencia de adquisición en tiempo de ejecución, desarrollado bajo la iniciativa ARCH-AUDIT-02. La clase LockSequence utiliza contextvars.ContextVar para rastrear el lock actualmente mantenido en cada contexto de ejecución asíncrona. Cuando se intenta adquirir un nuevo lock, el context manager compara su orden numérico definido en la enumeración LockOrder con el del lock actual. Si el nuevo lock tiene un orden menor o igual al actual, se lanza DeadlockRiskError inmediatamente con información detallada sobre ambos locks, antes de que pueda ocurrir el bloqueo que sería imposible de diagnosticar. Esta detección convierte bugs potencialmente catastróficos de deadlock en excepciones claras durante desarrollo.

El LockManager incluye además lógica de limpieza automática para evitar la acumulación infinita de locks en memoria que ocurriría si cada nueva sucursal o usuario creara un lock permanente. Se definen constantes que establecen un máximo de quinientos locks cacheados como MAX_CACHED_LOCKS, con un umbral de limpieza LOCK_CLEANUP_THRESHOLD al ochenta por ciento de capacidad que dispara la limpieza cuando se alcanza. Un ratio de histéresis LOCK_CLEANUP_HYSTERESIS_RATIO del ochenta por ciento previene el fenómeno de thrashing donde la limpieza ocurriría demasiado frecuentemente alternando entre estados de limpiar y llenar.

---

## Capítulo 6: Ciclo de Vida de Conexiones

El módulo ConnectionLifecycle ubicado en core/connection/lifecycle.py encapsula toda la lógica de aceptación y limpieza de conexiones, proporcionando una interfaz clara para el registro y desregistro de clientes WebSocket con manejo robusto de errores y condiciones excepcionales.

El proceso de conexión sigue una secuencia cuidadosamente ordenada de verificaciones y registros diseñada para fallar rápidamente ante condiciones inválidas. Primero se verifica si el servidor está en proceso de shutdown consultando una bandera interna, rechazando conexiones nuevas durante el cierre gracioso para evitar registrar conexiones que inmediatamente serían cerradas. Luego se validan los parámetros proporcionados incluyendo los branch_ids del usuario que deben ser una lista no vacía, y para mozos, los sector_ids asignados que determinan qué eventos recibirán. La validación incluye advertencias de logging para patrones sospechosos como mozos con más de diez sectores asignados o identificadores duplicados en las listas, que podrían indicar configuración incorrecta en el sistema de administración o intentos de manipulación.

La verificación del límite global de conexiones ocurre de manera atómica bajo el connection_counter_lock para prevenir condiciones de carrera donde múltiples conexiones simultáneas podrían exceder el límite. Si el servidor está a capacidad máxima de mil conexiones, se incrementa el contador de conexiones rechazadas en las métricas para monitoreo, se registra un warning con detalles de la conexión rechazada, y se lanza una excepción indicando la condición que el endpoint traducirá en un cierre con código apropiado. Si hay capacidad disponible, se incrementa el contador de conexiones activas antes de liberar el lock, reservando el espacio para esta conexión.

La aceptación del WebSocket se realiza llamando a websocket.accept() con un timeout configurable mediante asyncio.wait_for para prevenir conexiones colgadas que consumirían recursos indefinidamente esperando un handshake que nunca completa. El timeout por defecto es de diez segundos, suficiente para conexiones lentas pero no tanto como para desperdiciar recursos en clientes problemáticos. Si la aceptación falla por timeout, excepción de WebSocket, o cualquier otra excepción, se decrementa el contador de conexiones que fue incrementado previamente antes de propagar el error, manteniendo la consistencia del estado interno del contador.

Finalmente, el registro en índices añade la conexión a todas las estructuras de datos relevantes según los atributos del usuario autenticado. Se registra en el índice by_user con el user_id, en by_branch para cada branch_id autorizado iterando sobre la lista, en los mappings inversos _ws_to_user y _ws_to_tenant, y para mozos en by_sector para cada sector_id asignado. Para administradores se registra adicionalmente en admins_by_branch, y para personal de cocina en kitchen_by_branch.

El proceso de desconexión realiza las operaciones inversas de manera robusta, tolerando el caso donde algunos índices ya fueron limpiados por operaciones concurrentes. Se remueve la conexión de cada índice donde fue registrada utilizando discard() en lugar de remove() para que la ausencia del elemento no cause excepción. Los mappings inversos se eliminan con pop() usando default None. El contador global se decrementa bajo el lock correspondiente. Esta robustez es necesaria porque una conexión puede ser limpiada tanto por un cierre normal iniciado por el cliente como por la tarea de limpieza de conexiones muertas, y ambos paths deben funcionar correctamente sin importar cuál ejecuta primero.

---

## Capítulo 7: Broadcasting Paralelo y Worker Pool

El módulo ConnectionBroadcaster ubicado en core/connection/broadcaster.py representa una de las optimizaciones más significativas del Gateway, implementando un sistema de envío paralelo que reduce dramáticamente el tiempo de distribución de mensajes a grandes audiencias de cuatro segundos a aproximadamente ciento sesenta milisegundos para cuatrocientas conexiones.

El broadcaster mantiene un pool de diez workers configurables que procesan envíos de mensajes concurrentemente, implementados como tareas asíncronas que ejecutan loops infinitos consumiendo de una cola compartida. Durante el startup de la aplicación llamando al método initialize(), se crea una cola asíncrona asyncio.Queue con capacidad máxima de cinco mil tareas pendientes. Esta capacidad acotada proporciona backpressure cuando el sistema experimenta picos de carga: si los workers no pueden procesar tan rápido como llegan los envíos, la cola eventualmente se llena y los intentos de encolar nuevas tareas esperan, propagando la presión hacia atrás en lugar de consumir memoria infinitamente.

Cada worker ejecuta un loop infinito en el método _worker que consume tareas de la cola compartida. El loop espera una tarea llamando a queue.get() con un timeout de un segundo mediante wait_for, permitiendo verificar periódicamente la bandera _running para determinar si el worker debe detenerse durante el shutdown. Cuando una tarea llega, el worker extrae los tres elementos de la tupla: el WebSocket destinatario, el payload serializado a enviar, y un asyncio.Future opcional para reportar el resultado. El envío se realiza llamando a websocket.send_text() capturando cualquier excepción. El resultado booleano indicando éxito o fallo se registra en el Future si fue proporcionado mediante set_result(), permitiendo al código llamante contar cuántos envíos fueron exitosos versus fallidos para métricas.

El shutdown del worker pool procede de manera ordenada para permitir que envíos en progreso completen. Se establece la bandera _running en False indicando que los workers deben detenerse. Luego se espera la finalización de todos los workers con asyncio.gather usando un timeout configurable de cinco segundos. Los workers que no terminen dentro del timeout porque están procesando envíos lentos se cancelan forzosamente mediante cancel() en cada tarea, asegurando que el shutdown no se bloquee indefinidamente ante conexiones problemáticas.

El broadcaster implementa una estrategia híbrida que selecciona automáticamente el método de envío óptimo según el tamaño del broadcast, balanceando entre overhead de coordinación del worker pool y paralelismo efectivo. Para broadcasts pequeños con cincuenta conexiones o menos, el sistema utiliza el modo legacy que procesa en lotes secuenciales mediante asyncio.gather() con return_exceptions=True. Este enfoque tiene menor overhead de coordinación ya que no requiere encolar tareas y esperar Futures, siendo más eficiente para audiencias reducidas donde el paralelismo adicional no justifica el costo.

Para broadcasts grandes que superan las cincuenta conexiones, el sistema activa el modo de worker pool encolando cada envío como una tupla en la cola compartida. Cada tupla contiene el WebSocket destinatario, el payload ya serializado, y un Future creado con loop.create_future() para rastrear el resultado. Los diez workers procesan estas tareas en paralelo verdadero, distribuyendo el trabajo de envío entre múltiples contextos de ejecución simultáneos. Al finalizar, se recolectan todos los Futures para contar éxitos y fallos que se registran en métricas.

Las mediciones de rendimiento demuestran el impacto transformador de esta optimización. Un broadcast a cuatrocientas conexiones que tomaría aproximadamente cuatro segundos en modo secuencial puro se completa en alrededor de ciento sesenta milisegundos usando el worker pool, una mejora de veinticinco veces que resulta crítica para mantener la sensación de tiempo real en la interfaz de usuario donde delays perceptibles destruirían la experiencia.

---

## Capítulo 8: Aislamiento Multi-Tenant

El TenantFilter ubicado en components/broadcast/tenant_filter.py garantiza aislamiento estricto entre diferentes restaurantes que comparten la infraestructura del Gateway. Este componente actúa como guardián que previene fugas de información entre organizaciones, un requerimiento crítico de seguridad y privacidad en un sistema multi-tenant.

El filtrado opera verificando que cada conexión candidata pertenezca al mismo tenant_id que el evento siendo distribuido. Cuando un evento especifica un tenant_id en su payload, el filtro examina cada conexión consultando el mapping inverso _ws_to_tenant y verifica que el valor coincida exactamente. Las conexiones sin tenant_id asociado en el mapping o con un tenant_id diferente se excluyen silenciosamente del broadcast sin generar errores, simplemente no reciben el mensaje. Si el evento no especifica tenant_id con valor null o ausente, el filtro permite todas las conexiones pasar, comportamiento útil para mensajes del sistema, broadcasts globales autorizados, o eventos de infraestructura que no contienen datos de negocio sensibles.

Un aspecto crítico del diseño identificado como CRIT-DEEP-02 FIX es que el filtrado por tenant ocurre dentro del lock de rama, no después de liberarlo. Esta decisión previene una condición de carrera sutil pero peligrosa que sería difícil de detectar en testing pero catastrófica en producción. Si el filtrado ocurriera después de liberar el lock, nuevas conexiones de otros tenants podrían registrarse entre el momento de liberar el lock y el momento del envío, potencialmente recibiendo mensajes destinados a otro tenant. Al filtrar dentro del lock, se garantiza una vista consistente de las conexiones durante toda la operación de broadcast, eliminando la ventana de vulnerabilidad.

El método filter_connections implementa el filtrado recibiendo una lista de conexiones y el tenant_id objetivo. Si tenant_id es None, retorna la lista sin modificación. Si tiene valor, itera sobre las conexiones construyendo una nueva lista solo con aquellas cuyo tenant_id en el mapping coincide. El resultado se retorna para que el broadcaster proceda con el envío solo a las conexiones autorizadas.

---

## Capítulo 9: Suscripción a Eventos Redis

El RedisSubscriber ubicado en redis_subscriber.py establece una conexión persistente con Redis y escucha eventos publicados por la API REST, actuando como puente entre el backend que genera eventos y las conexiones WebSocket que los consumen. Tras la refactorización ARCH-MODULAR-09, se transformó en un orquestador delgado de aproximadamente trescientas veintiséis líneas que coordina módulos especializados para validación, tracking de eventos perdidos, y procesamiento.

El suscriptor utiliza el patrón Pub/Sub de Redis con suscripciones por patrón mediante psubscribe, permitiendo escuchar dinámicamente todos los canales que coincidan con ciertos patrones sin necesidad de conocer de antemano los identificadores específicos de sucursales, sectores y sesiones que varían entre instalaciones y cambian en tiempo de ejecución cuando se crean o eliminan entidades.

El sistema define cinco patrones de canales principales registrados en WSConstants. El patrón branch:*:waiters captura eventos destinados a mozos de cualquier sucursal, como notificaciones de nuevos pedidos o llamadas de servicio. El patrón branch:*:kitchen captura eventos para personal de cocina, incluyendo comandas nuevas y actualizaciones de estado de preparación. El patrón branch:*:admin captura eventos para administradores y managers con visibilidad completa de la operación. El patrón sector:*:waiters permite notificaciones dirigidas a mozos de sectores específicos, útil cuando un evento solo es relevante para el personal de cierta área del restaurante. El patrón session:* captura eventos para comensales de sesiones específicas, como actualizaciones del estado de su pedido individual.

El loop principal del suscriptor mantiene una cola interna de eventos pendientes implementada como collections.deque con capacidad máxima de cinco mil elementos que proporciona backpressure natural. Cuando llega un mensaje de Redis mediante get_message(), se valida usando el módulo validator y se encola si es válido. Durante períodos de inactividad cuando get_message() retorna None porque no hay mensajes pendientes, se procesa la cola acumulada en lotes de hasta cincuenta eventos, distribuyendo la carga de procesamiento de manera eficiente sin bloquear la recepción de nuevos mensajes.

El módulo EventDropRateTracker ubicado en core/subscriber/drop_tracker.py monitorea la salud del pipeline de eventos como singleton global, generando alertas cuando la tasa de eventos perdidos supera umbrales configurados. El tracker mantiene una ventana deslizante implementada como deque de tuplas con timestamp, eventos procesados y eventos perdidos. Cuando se registra un evento perdido mediante record_drop(), el tracker calcula la tasa de pérdida sobre la ventana actual de sesenta segundos. Si esta tasa supera el umbral configurado del cinco por ciento, se genera una alerta de nivel CRITICAL con detalles sobre la tasa actual y el umbral. Un cooldown de cinco minutos entre alertas previene la saturación del sistema de logging durante problemas sostenidos que generarían alertas cada pocos segundos.

---

## Capítulo 10: Validación de Eventos y Enrutamiento

El módulo validator.py en core/subscriber verifica que los eventos contengan los campos requeridos antes del procesamiento, actuando como primera línea de defensa contra eventos malformados, corruptos, o maliciosamente construidos que podrían causar errores en el procesamiento posterior.

El sistema define conjuntos inmutables frozensets de campos requeridos y opcionales que no pueden modificarse en runtime. Los campos requeridos incluyen type que indica el tipo de evento como ROUND_SUBMITTED o TABLE_SESSION_STARTED, tenant_id que identifica el restaurante origen, y branch_id que identifica la sucursal específica. Los campos opcionales incluyen session_id para eventos relacionados con sesiones de mesa, sector_id para eventos que deben filtrarse por sector, table_id para eventos de mesa específica, entity para el payload de datos del evento, y otros específicos de ciertos tipos.

La función de validación validate_event_schema implementa verificación pura sin efectos secundarios, retornando una tupla de booleano indicando validez y string con información de diagnóstico. Primero verifica que el dato sea un diccionario usando isinstance, rechazando listas, strings u otros tipos con razón not_dict. Segundo verifica que todos los campos requeridos estén presentes iterando sobre REQUIRED_FIELDS y construyendo lista de faltantes, rechazando con razón missing_fields:type,branch_id si hay campos ausentes. Tercero verifica que el tipo de evento sea uno de los tipos conocidos consultando el conjunto VALID_EVENT_TYPES, rechazando con razón unknown_type:INVALID_EVENT si es desconocido.

El EventRouter ubicado en components/events/router.py centraliza la lógica de enrutamiento determinando qué conexiones deben recibir cada tipo de evento basándose en el canal de origen y el tipo de evento. El router mantiene conjuntos inmutables que clasifican eventos por su audiencia objetivo. SESSION_EVENTS contiene eventos que deben llegar a comensales de sesiones específicas como ROUND_READY o CART_ITEM_ADDED. BRANCH_WIDE_EVENTS contiene eventos que deben llegar a toda la sucursal sin filtrado de sector como ROUND_PENDING y TABLE_SESSION_STARTED, necesarios para que cualquier mozo cercano pueda atender.

El método route_event recibe el evento validado y el canal de origen, retornando una lista de conexiones destinatarias. Extrae el tipo de evento y los identificadores relevantes del payload. Consulta el ConnectionIndex para obtener las conexiones candidatas según el tipo de canal. Aplica el TenantFilter para garantizar aislamiento multi-tenant. Para eventos de mozo, verifica si el evento está en BRANCH_WIDE_EVENTS para determinar si debe enviarse a todos los mozos o solo a los del sector especificado.

---

## Capítulo 11: Autenticación mediante Estrategias

El Gateway implementa el patrón Strategy para soportar diferentes métodos de autenticación de manera extensible y mantenible. Las clases de estrategia residen en el módulo components/auth/strategies.py y encapsulan toda la lógica de verificación de credenciales, permitiendo agregar nuevos métodos de autenticación sin modificar código existente.

El resultado de autenticación se representa mediante la dataclass inmutable AuthResult con frozen=True y slots=True para optimización de memoria. La dataclass encapsula el éxito o fallo de la autenticación junto con información contextual. El campo success indica si la autenticación fue exitosa. El campo data contiene los datos extraídos del token para éxitos, como claims del JWT o datos del table token. El campo error contiene el mensaje de error para fallos. El campo close_code contiene el código de cierre WebSocket apropiado para fallos. El campo audit_reason proporciona información para logging de seguridad. Los métodos de clase ok(), fail() y forbidden() proporcionan constructores convenientes para los casos comunes con valores predeterminados apropiados.

La estrategia JWTAuthStrategy maneja autenticación mediante tokens JWT para personal del restaurante incluyendo mozos, cocina y administradores. El constructor recibe la lista de roles requeridos para el endpoint específico. El método authenticate ejecuta una secuencia de verificaciones. Primero valida el origen de la conexión WebSocket contra la lista de orígenes permitidos llamando a validate_websocket_origin, rechazando conexiones de orígenes desconocidos con código FORBIDDEN y razón invalid_origin. Segundo verifica la firma y validez del JWT llamando a verify_jwt del módulo de seguridad compartido, rechazando tokens expirados o malformados con código AUTH_FAILED. La estrategia rechaza específicamente tokens que contienen el claim token_type con valor refresh, que son refresh tokens que solo deben usarse para obtener nuevos access tokens y no para autenticación directa de WebSocket. Finalmente verifica que el usuario tenga al menos uno de los roles requeridos comparando la lista de roles del token con required_roles.

La estrategia TableTokenAuthStrategy maneja autenticación mediante tokens HMAC para comensales conectados a sesiones de mesa. Estos tokens no contienen roles ya que los comensales no tienen identidad de usuario en el sistema tradicional de gestión de personal. El método authenticate primero valida el origen de la conexión. Luego valida criptográficamente el token HMAC llamando a verify_table_token que verifica la firma usando la clave secreta configurada. El token contiene información sobre session_id, branch_id y tenant_id que se extraen y retornan en el AuthResult para uso posterior durante el registro de la conexión.

---

## Capítulo 12: Endpoints WebSocket y Jerarquía de Clases

Los endpoints WebSocket heredan de clases base que encapsulan comportamiento común, eliminando aproximadamente trescientas líneas de código duplicado que existían cuando cada endpoint implementaba su propio ciclo de vida completo con lógica repetida de autenticación, registro, loop de mensajes y limpieza.

La clase abstracta WebSocketEndpointBase ubicada en components/endpoints/base.py define el ciclo de vida completo de un endpoint como template method. El constructor acepta el WebSocket de la conexión, el ConnectionManager para registro, y un nombre de endpoint utilizado para logging contextual y métricas. El método run() ejecuta la secuencia completa del ciclo de vida: primero llama validate_auth() para verificar credenciales, luego create_context() para construir el contexto de usuario, después register_connection() para añadir a índices, ejecuta el loop de mensajes llamando a _message_loop(), y finalmente en bloque finally llama unregister_connection() para garantizar limpieza incluso ante excepciones inesperadas.

La clase define cuatro métodos abstractos mediante @abstractmethod que las subclases deben implementar proporcionando la lógica específica de cada tipo de endpoint. El método validate_auth() realiza la autenticación específica y retorna los datos extraídos del token como diccionario, o None si la autenticación falla indicando que la conexión debe cerrarse. El método create_context() construye un objeto WebSocketContext con la información del usuario autenticado para uso durante el ciclo de vida. El método register_connection() añade la conexión a los índices apropiados del ConnectionManager según el tipo de usuario. El método unregister_connection() realiza la limpieza inversa removiendo de índices cuando la conexión termina.

La clase JWTWebSocketEndpoint extiende la base añadiendo autenticación JWT y revalidación periódica para conexiones de larga duración. El constructor adicional acepta el token JWT como string y la lista de roles requeridos. La implementación de validate_auth() instancia JWTAuthStrategy con los roles requeridos e invoca authenticate(). El método _message_loop() sobrescrito incluye verificación periódica cada cinco minutos del intervalo JWT_REVALIDATION_INTERVAL, verificando que el token siga siendo válido consultando la lista de revocación en Redis y comprobando que no haya expirado. Si la revalidación falla porque el token fue revocado o expiró, la conexión se cierra con código AUTH_FAILED.

El WaiterEndpoint extiende JWTWebSocketEndpoint con funcionalidad específica para personal de servicio. Durante create_context() extrae información del JWT y consulta las asignaciones de sector actuales llamando a get_waiter_sector_ids() del SectorAssignmentRepository. Durante register_connection() invoca al manager indicando is_admin basado en el rol y proporcionando sector_ids. El endpoint implementa el comando especial refresh_sectors que permite actualizar asignaciones de sector sin desconectarse, útil cuando un supervisor reasigna sectores durante el turno. Al recibir el comando, revalida el JWT, consulta nuevas asignaciones, actualiza índices del manager, y envía confirmación al cliente.

El KitchenEndpoint es más simple, aceptando roles KITCHEN, MANAGER y ADMIN, registrando con is_kitchen=True para indexación en kitchen_by_branch. El AdminEndpoint proporciona visibilidad completa de sucursal registrando con is_admin=True. El DinerEndpoint difiere significativamente usando TableTokenAuthStrategy en lugar de JWT, registrando con user_id pseudo-negativo derivado de session_id para evitar colisiones, y en el índice de sesiones para recibir eventos de mesa.

---

## Capítulo 13: Rate Limiting y Protección

El WebSocketRateLimiter ubicado en components/connection/rate_limiter.py previene que conexiones individuales abusen del sistema enviando mensajes a tasas excesivas, ya sea por error de programación en el cliente como un loop infinito, o por intento malicioso de agotar recursos del servidor.

El limiter mantiene un diccionario que mapea cada WebSocket a una deque de timestamps de mensajes recientes con maxlen igual al límite para auto-evicción de timestamps antiguos. El método is_allowed implementa verificación en dos pasos. Primero obtiene o crea la deque para la conexión, limpiando timestamps que han salido de la ventana de tiempo de un segundo comparando con el tiempo actual. Segundo cuenta cuántos timestamps permanecen en la deque. Si el conteo es menor al límite de veinte mensajes por defecto, añade el timestamp actual y retorna True permitiendo el mensaje. Si el conteo alcanza o supera el límite, retorna False indicando rechazo.

Las conexiones que exceden el límite de veinte mensajes por segundo reciben código de cierre 4029 asignado en WSCloseCode.RATE_LIMITED, un código personalizado en el rango 4000+ que permite a los clientes distinguir entre un cierre por rate limiting versus otros tipos de cierre como autenticación o política. Un cliente bien implementado podría reconectarse después de un breve delay de backoff, mientras que uno defectuoso debería investigar por qué está generando tantos mensajes.

El módulo components/redis/lua_scripts.py implementa rate limiting atómico adicional usando scripts Lua ejecutados directamente en Redis para operaciones que requieren atomicidad garantizada entre múltiples claves o comandos. El problema con operaciones Redis separadas como GET seguido de INCREMENT es que entre leer el contador actual y escribir el nuevo valor, otra request podría leer el mismo valor original, resultando en un conteo incorrecto que permite más requests de las autorizadas. Los scripts Lua se ejecutan atómicamente en el servidor Redis como una única operación indivisible, garantizando que toda la secuencia ocurre sin interrupciones de otras operaciones.

El script RATE_LIMIT_SCRIPT recibe como argumentos el key de Redis, el límite máximo, el tamaño de ventana en segundos, y el timestamp actual. Primero obtiene el contador actual con GET. Si el contador existe y está en el límite, retorna inmediatamente una tupla indicando rechazo junto con el conteo actual y el TTL restante para que el cliente sepa cuánto esperar. Si hay espacio disponible, incrementa el contador con INCR y establece el TTL con EXPIRE si es el primer incremento de la ventana. Finalmente retorna éxito con el nuevo conteo y TTL.

---

## Capítulo 14: Heartbeat y Limpieza de Conexiones

El HeartbeatTracker ubicado en components/connection/heartbeat.py mantiene un registro preciso de la última actividad de cada conexión, permitiendo identificar y cerrar conexiones que han quedado inactivas por problemas de red, clientes congelados, o desconexiones no detectadas.

El tracker mantiene un diccionario _timestamps que mapea cada WebSocket al timestamp flotante de su último heartbeat registrado. Un threading.Lock protege esta estructura para operaciones thread-safe, necesario porque algunas operaciones de limpieza pueden ejecutarse desde contextos síncronos mientras el registro de heartbeats ocurre en contextos async. El timeout por defecto se configura en sesenta segundos, significando que conexiones sin actividad reportada por más de un minuto se consideran stale y candidatas para cierre.

El protocolo de heartbeat funciona como un intercambio simple de mensajes de vida entre cliente y servidor. El cliente envía un mensaje con type igual a ping cada treinta segundos como keep-alive. El servidor al recibir este mensaje responde inmediatamente con un mensaje type pong y llama a tracker.record(websocket) para actualizar el timestamp de la conexión en el diccionario interno. La tarea heartbeat_cleanup_task ejecuta cada treinta segundos en background, llamando a tracker.get_stale_connections() para identificar conexiones cuyo último heartbeat ocurrió hace más del timeout. Las conexiones identificadas como stale se cierran con código 1001 GOING_AWAY, indicando que el servidor está terminando la conexión debido a inactividad detectada.

El ConnectionCleanup implementa un patrón de dos fases para la limpieza que evita el error RuntimeError de dictionary changed size during iteration que ocurriría si se modificara el diccionario de conexiones mientras se itera sobre él durante la limpieza. En la primera fase de snapshot, se toma una copia de las conexiones stale bajo el lock del tracker mediante list(). En la segunda fase de cierre, se procede a cerrar cada conexión fuera del lock ya que las operaciones de I/O de red no deben bloquear otras operaciones del tracker que podrían estar registrando heartbeats de otras conexiones. En la tercera fase de desregistro, se desregistra cada conexión del ConnectionIndex con una verificación adicional double-check consultando si la conexión aún existe antes de intentar removerla, manejando el caso donde la conexión ya fue desregistrada por otra operación concurrente como un cierre normal iniciado por el cliente.

---

## Capítulo 15: Circuit Breaker para Resiliencia Redis

El CircuitBreaker ubicado en components/resilience/circuit_breaker.py protege al Gateway contra cascadas de fallos cuando Redis experimenta problemas de conectividad, saturación, o rendimiento degradado que causarían timeouts acumulados.

El circuit breaker implementa tres estados distintos representados en la enumeración CircuitState. En estado CLOSED las operaciones proceden normalmente y el breaker simplemente monitorea contando éxitos y fallos consecutivos. Cuando el contador de fallos consecutivos alcanza el umbral configurable de cinco por defecto, el breaker transiciona a estado OPEN donde todas las operaciones se rechazan inmediatamente sin intentar contactar Redis, previniendo la acumulación de timeouts que degradarían el rendimiento general y potencialmente agotarían recursos como threads o conexiones de pool. Después del timeout de recuperación de treinta segundos por defecto, el breaker transiciona automáticamente a estado HALF_OPEN donde permite un número limitado de operaciones de prueba para verificar si Redis se ha recuperado. Si estas pruebas tienen éxito registrado mediante record_success(), el breaker regresa a CLOSED; si fallan con record_failure(), vuelve a OPEN por otro período de timeout.

Un aspecto crítico de la implementación identificado como CRIT-AUD-01 FIX es el uso de un único threading.Lock para todas las operaciones de sincronización que modifican o leen estado interno. Las implementaciones anteriores que mezclaban asyncio.Lock para operaciones async y threading.Lock para operaciones sync experimentaban race conditions cuando ambos tipos de operaciones modificaban el mismo estado del breaker simultáneamente. El lock unificado basado en threading funciona correctamente en ambos contextos de ejecución, garantizando consistencia del estado interno sin importar desde qué tipo de código se invoque.

El método get_stats proporciona información sobre el estado actual del breaker para health checks y métricas. Este método también adquiere el lock antes de leer estado para garantizar un snapshot consistente sin lecturas parciales, identificado como MED-DEEP-01 FIX. Retorna un diccionario con el estado actual como string, el contador de fallos recientes, el número de operaciones rechazadas mientras estuvo abierto, y el timestamp de la última transición de estado.

---

## Capítulo 16: Redis Streams para Eventos Críticos

Además del sistema Pub/Sub tradicional que proporciona entrega best-effort, el Gateway implementa un consumidor completo de Redis Streams para eventos críticos que requieren entrega garantizada como pagos y estados de pedido importantes. Esta funcionalidad desarrollada bajo la iniciativa ARCH-STREAM-01 complementa Pub/Sub proporcionando semánticas de at-least-once delivery donde los mensajes nunca se pierden aunque puedan entregarse más de una vez.

Redis Streams difiere fundamentalmente de Pub/Sub en su modelo de persistencia y entrega. Mientras Pub/Sub descarta mensajes inmediatamente si no hay suscriptores activos en el momento exacto de publicación, Streams persiste los mensajes en el servidor Redis y permite a los consumidores procesarlos a su propio ritmo, retomando desde donde quedaron después de desconexiones. Los Consumer Groups permiten que múltiples instancias del Gateway compartan el procesamiento de un stream distribuyendo mensajes entre ellas, con Redis rastreando internamente qué mensajes ha procesado cada consumidor mediante la Pending Entries List.

El StreamConsumer implementa el patrón de Consumer Group con varias características robustas de producción. Durante la inicialización en el método start(), crea el Consumer Group si no existe usando XGROUP CREATE con la opción MKSTREAM para crear también el stream subyacente si es necesario, evitando errores en instalaciones nuevas donde los streams aún no existen. El loop principal lee lotes de mensajes usando XREADGROUP con el especificador mayor-que para recibir solo mensajes nuevos, con un timeout de bloqueo BLOCK de mil milisegundos que permite verificar periódicamente si el consumidor debe detenerse durante shutdown.

La recuperación de mensajes pendientes constituye una característica distintiva del consumidor que garantiza que ningún mensaje se pierda por fallos de instancias. Redis mantiene una Pending Entries List con mensajes que fueron entregados a consumidores pero nunca confirmados mediante XACK, típicamente porque el consumidor murió antes de completar el procesamiento exitoso. Cada treinta ciclos del loop principal, el consumidor ejecuta XAUTOCLAIM para reclamar mensajes que han estado pendientes por más de treinta segundos, presumiblemente abandonados por consumidores fallidos de otras instancias. Cada mensaje recuperado incrementa un contador de reintentos almacenado en los metadatos; aquellos que exceden tres reintentos se mueven a la Dead Letter Queue ya que probablemente tienen un problema inherente que impide su procesamiento exitoso.

La Dead Letter Queue implementada bajo RES-LOW-01 proporciona un destino para mensajes que no pueden procesarse exitosamente después de múltiples intentos. En lugar de descartar estos mensajes perdiendo datos potencialmente valiosos, el sistema los preserva en un stream separado con sufijo :dlq junto con metadatos ricos. Se almacena el stream de origen, el ID del mensaje original, el payload serializado como JSON, la razón del fallo o excepción capturada, el contador de reintentos alcanzado, y el timestamp del momento del fallo. Este registro permite análisis posterior para identificar patrones de fallo, debugging de problemas de integración, y recuperación manual de datos si es necesario.

El backoff exponencial con jitter protege contra el thundering herd cuando múltiples consumidores intentan reconectarse simultáneamente después de una falla de Redis que afectó a todas las instancias. El delay base de un segundo se multiplica exponencialmente por dos elevado al número de intento hasta un máximo de sesenta segundos. El jitter decorrelacionado implementado en DecorrelatedJitter añade aleatoriedad eligiendo un valor uniforme entre el delay base y el delay calculado, distribuyendo los reintentos en el tiempo para evitar oleadas sincronizadas que sobrecargarían el servidor Redis en recuperación.

---

## Capítulo 17: Métricas y Observabilidad

El MetricsCollector ubicado en components/metrics/collector.py centraliza estadísticas del Gateway con operaciones diseñadas para funcionar correctamente tanto en contextos asíncronos como síncronos sin causar deadlocks o inconsistencias.

El collector agrupa métricas en categorías representadas como dataclasses internas. BroadcastMetrics contiene total de broadcasts enviados, cantidad con fallos parciales o totales, y cantidad rechazados por rate limiting global. ConnectionMetrics contiene rechazos por límite de capacidad alcanzado y rechazos por rate limiting individual. EventMetrics contiene total procesados exitosamente y perdidos desglosados por razón incluyendo esquema inválido, sin destinatarios, y circuit breaker abierto.

La implementación utiliza dos locks separados identificado como CRIT-WS-08 FIX. Un asyncio.Lock para operaciones asíncronas normales que constituyen la mayoría del código del Gateway. Un threading.Lock para operaciones síncronas que ocurren en ciertos paths como callbacks de bibliotecas externas o código de limpieza. Esta dualidad resuelve problemas que ocurrían cuando operaciones del mismo contador se ejecutaban desde diferentes contextos de ejecución que requerían diferentes tipos de lock. Los métodos vienen en pares: increment_broadcast_total() para uso async adquiriendo el lock async, y increment_broadcast_total_sync() para uso sync adquiriendo el lock de threading.

El método get_snapshot_sync() proporciona una vista consistente de todas las métricas en un momento dado, utilizado para health checks detallados y el endpoint de métricas Prometheus. El snapshot se captura bajo el lock sync para asegurar que todos los valores corresponden al mismo instante sin actualizaciones parciales que darían una vista inconsistente.

El PrometheusFormatter ubicado en components/metrics/prometheus.py formatea las métricas para exposición en el endpoint /ws/metrics siguiendo la especificación de Prometheus. Cada métrica incluye líneas de comentario con HELP describiendo qué mide en lenguaje humano, y TYPE indicando si es counter para valores siempre crecientes, gauge para valores que pueden subir y bajar, o histogram para distribuciones. El formato permite labels entre llaves para dimensionar métricas, por ejemplo wsgateway_events_dropped_total con label reason igual a invalid_schema versus reason igual a no_recipients. Las métricas clave expuestas incluyen conexiones totales desde startup, conexiones activas actuales, broadcasts totales y fallidos, y estado del circuit breaker como gauge numérico.

---

## Capítulo 18: Flujo Completo de un Evento en Práctica

Cuando un comensal confirma su pedido en la aplicación pwaMenu, se desencadena una secuencia de eventos que ilustra el funcionamiento integrado de todo el sistema desde la acción del usuario hasta la notificación en todas las pantallas relevantes.

El proceso comienza en la API REST donde el endpoint de creación de rondas valida el pedido contra el menú vigente, lo persiste en PostgreSQL con estado PENDING, y procede a notificar a las partes interesadas. La función publish_round_event construye el payload del evento y publica a múltiples canales Redis usando el pool async. Primero al canal branch seguido del branch_id y :waiters para que los mozos sepan que hay un nuevo pedido por verificar en la mesa. Luego al canal branch seguido del branch_id y :admin para visibilidad en el Dashboard de gestión donde los administradores monitorizan la operación.

El RedisSubscriber del Gateway recibe ambos mensajes a través de su suscripción por patrón que captura todos los canales que coinciden con branch:*:waiters y branch:*:admin. Cada mensaje pasa por validación de esquema en el módulo validator que verifica la presencia de los campos requeridos type, tenant_id y branch_id, y que el tipo de evento ROUND_PENDING sea uno de los tipos válidos registrados en el conjunto VALID_EVENT_TYPES.

El EventRouter determina los destinatarios apropiados según el canal de origen parseando el nombre del canal. El mensaje del canal branch:5:waiters se rutea consultando el índice by_branch para obtener conexiones de mozos de la sucursal cinco, verificando que ROUND_PENDING está en BRANCH_WIDE_EVENTS para enviarlo a todos los mozos sin filtrado de sector. El mensaje del canal branch:5:admin se rutea a las conexiones en el índice admins_by_branch con clave cinco.

Antes del envío, el TenantFilter verifica dentro del lock de rama que cada conexión candidata pertenezca al mismo tenant_id que el evento consultando el mapping inverso, garantizando que restaurantes diferentes que comparten la infraestructura no reciban eventos ajenos. El ConnectionBroadcaster evalúa el número de destinatarios y selecciona el método de envío apropiado. Para unas pocas conexiones usa el modo legacy con asyncio.gather. Para muchas conexiones encola en el worker pool para envío paralelo.

En el Dashboard, la recepción del evento ROUND_PENDING activa la lógica de actualización visual en el store de mesas. La mesa correspondiente muestra una animación de pulso amarillo indicando orden pendiente, el badge de estado cambia a mostrar Pendiente en amarillo, y si el administrador tiene habilitadas las notificaciones de audio, suena un sonido discreto. En pwaWaiter, los mozos ven una notificación de nuevo pedido que requiere verificación física en la mesa antes de poder avanzar el estado.

Cuando el mozo verifica el pedido y el administrador lo envía a cocina con estado SUBMITTED, el KitchenEndpoint recibe el evento ROUND_SUBMITTED y lo entrega a las conexiones en kitchen_by_branch. Las terminales de cocina muestran la nueva comanda en la columna Nuevos, listando los productos a preparar con sus modificaciones y notas especiales del comensal. Este flujo completo desde que el comensal toca el botón hasta que ve la confirmación y la cocina recibe la comanda típicamente toma menos de doscientos milisegundos de transmisión a través del Gateway, creando la ilusión de actualizaciones instantáneas.

---

## Conclusión

El WebSocket Gateway representa el sistema nervioso central del ecosistema Integrador, transmitiendo información en tiempo real entre todos los actores de un restaurante desde comensales hasta personal de cocina. Su arquitectura modular, resultado de la refactorización ARCH-MODULAR, separó responsabilidades en componentes especializados ubicados en los directorios core y components que pueden evolucionar independientemente sin afectar la estabilidad del sistema.

Los patrones implementados reflejan decisiones arquitectónicas orientadas tanto a la mantenibilidad como al rendimiento bajo carga. El sistema de locks fragmentados mediante el LockManager reduce la contención en aproximadamente noventa por ciento durante operaciones concurrentes, permitiendo que múltiples sucursales operen con total independencia. El mecanismo de LockSequence previene deadlocks validando el orden de adquisición en tiempo de ejecución, convirtiendo bugs potencialmente catastróficos en excepciones claras durante desarrollo.

El worker pool de broadcasting con diez workers reduce el tiempo de entrega de mensajes de cuatro segundos a ciento sesenta milisegundos para broadcasts de cuatrocientas conexiones, una mejora de veinticinco veces esencial para mantener la sensación de tiempo real. El circuit breaker con lock unificado previene cascadas de fallos cuando Redis experimenta problemas, permitiendo degradación graceful en lugar de colapso total del servicio.

El patrón Strategy para autenticación mediante JWTAuthStrategy y TableTokenAuthStrategy permite extensibilidad sin modificar código existente. El patrón Template Method en las clases de endpoint elimina trescientas líneas de código duplicado. El TenantFilter garantiza aislamiento multi-tenant filtrando dentro del lock para prevenir condiciones de carrera.

Los scripts Lua atómicos eliminan race conditions en rate limiting. El Stream Consumer con recuperación de mensajes pendientes garantiza entrega de eventos críticos incluso cuando instancias fallan. La Dead Letter Queue preserva mensajes fallidos para análisis en lugar de perderlos silenciosamente.

Esta arquitectura sustenta la experiencia fluida que los usuarios perciben al ver actualizaciones instantáneas en sus dispositivos, desde el momento que un comensal confirma su pedido hasta que el plato aparece marcado como listo en todas las pantallas del ecosistema, creando la sensación de un sistema vivo y reactivo que responde instantáneamente a cada acción.
