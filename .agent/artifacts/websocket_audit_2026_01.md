# üîç Auditor√≠a WebSocket - Proyecto Integrador

**Fecha**: 2026-01-31  
**Componente**: `ws_gateway` + Clientes Frontend (Dashboard, pwaWaiter, pwaMenu)  
**Versi√≥n**: 0.2.0

---

## Resumen Ejecutivo

| Categor√≠a | Estado | Cr√≠ticos | Altos | Medios | Bajos |
|-----------|--------|----------|-------|--------|-------|
| **Arquitectura** | ‚úÖ Excelente | 0 | 0 | 1 | 2 |
| **Seguridad** | ‚úÖ S√≥lida | 0 | 1 | 2 | 0 |
| **Resiliencia** | ‚úÖ Robusta | 0 | 0 | 2 | 1 |
| **Escalabilidad** | ‚ö†Ô∏è Mejorable | 0 | 2 | 1 | 0 |
| **Cliente-Side** | ‚úÖ Consistente | 0 | 0 | 1 | 2 |

**Calificaci√≥n General**: **8.5/10** - Sistema maduro con pr√°cticas s√≥lidas

---

## ‚úÖ Correcciones Implementadas en Esta Auditor√≠a

### Primera Ronda (Prioridad Alta)

| ID | Hallazgo | Archivo | Estado |
|----|----------|---------|--------|
| SEC-MED-02 | NON_RECOVERABLE_CLOSE_CODES incluye 4029 | Dashboard/websocket.ts | ‚úÖ Implementado |
| SEC-MED-02 | NON_RECOVERABLE_CLOSE_CODES incluye 4029 | pwaMenu/websocket.ts | ‚úÖ Implementado |
| SEC-MED-02 | NON_RECOVERABLE_CLOSE_CODES incluye 4029 | pwaWaiter/constants.ts | ‚úÖ Implementado |
| RES-MED-01 | Callback `onMaxReconnectReached` | pwaMenu/websocket.ts | ‚úÖ Implementado |
| RES-MED-01 | Callback `onMaxReconnectReached` | pwaWaiter/websocket.ts | ‚úÖ Implementado |
| CLIENT-MED-01 | MAX_RECONNECT_ATTEMPTS = 50 | pwaMenu/websocket.ts | ‚úÖ Implementado |
| CLIENT-MED-01 | MAX_RECONNECT_ATTEMPTS = 50 | pwaWaiter/constants.ts | ‚úÖ Implementado |
| CLIENT-LOW-02 | Listener cleanup (Sets vac√≠os) | pwaMenu/websocket.ts | ‚úÖ Implementado |

### Segunda Ronda (Prioridad Media y Baja)

| ID | Hallazgo | Archivo | Estado |
|----|----------|---------|--------|
| SEC-HIGH-01 | Revalidaci√≥n peri√≥dica de table tokens | ws_gateway/components/endpoints/handlers.py | ‚úÖ Implementado |
| SEC-HIGH-01 | Constante TABLE_TOKEN_REVALIDATION_INTERVAL | ws_gateway/components/core/constants.py | ‚úÖ Implementado |
| SEC-MED-01 | Doble verificaci√≥n environment | ws_gateway/components/core/constants.py | ‚úÖ Implementado |
| RES-MED-02 | Backoff exponencial en stream consumer | ws_gateway/core/subscriber/stream_consumer.py | ‚úÖ Implementado |
| RES-LOW-01 | DLQ f√≠sico con Redis XADD | ws_gateway/core/subscriber/stream_consumer.py | ‚úÖ Implementado |
| SCALE-HIGH-01 | Worker pool para broadcasts grandes | ws_gateway/core/connection/broadcaster.py | ‚úÖ Implementado |
| SCALE-HIGH-01 | Integraci√≥n lifespan | ws_gateway/main.py, connection_manager.py | ‚úÖ Implementado |
| SCALE-MED-01 | Lock sharding por tenant | ws_gateway/components/connection/locks.py | ‚úÖ Implementado |
| CLIENT-LOW-01 | onThrottled para eventos de alta frecuencia | pwaWaiter/websocket.ts | ‚úÖ Implementado |

### Tercera Ronda (Documentaci√≥n y Redis Best Practices)

| ID | Hallazgo | Archivo | Estado |
|----|----------|---------|--------|
| DOC-IMP-01 | Canales Redis extra√≠dos a constantes | ws_gateway/components/core/constants.py | ‚úÖ Implementado |
| DOC-IMP-01 | main.py usa WSConstants.REDIS_SUBSCRIPTION_CHANNELS | ws_gateway/main.py | ‚úÖ Implementado |
| DOC-IMP-02 | Constantes de Redis Streams documentadas | ws_gateway/components/core/constants.py | ‚úÖ Implementado |
| REDIS-01 | Pipeline helper para batch ACKs | ws_gateway/components/redis/lua_scripts.py | ‚úÖ Implementado |
| REDIS-02 | Lua script para rate limiting at√≥mico | ws_gateway/components/redis/lua_scripts.py | ‚úÖ Implementado |
| DOC-FIX-01 | socketGat.md actualizado con implementaci√≥n real | socketGat.md | ‚úÖ Implementado |

---

## 1. Arquitectura del Gateway

### 1.1 Patrones Positivos Implementados ‚úÖ

| Patr√≥n | Implementaci√≥n | Beneficio |
|--------|----------------|-----------|
| **Composition over Inheritance** | `ConnectionManager` delega a componentes especializados | Alta cohesi√≥n, bajo acoplamiento |
| **Strategy Pattern** | `AuthStrategy` con `JWTAuthStrategy` y `TableTokenAuthStrategy` | Autenticaci√≥n pluggable |
| **Circuit Breaker** | Implementado para Redis subscriber | Prevenci√≥n de cascading failures |
| **Singleton (Lazy)** | `EventRouter` singleton en `main.py` | Reduce creaci√≥n de objetos |
| **Lock Ordering** | Documentado y aplicado: User ‚Üí Branch ‚Üí Sector/Session | Prevenci√≥n de deadlocks |
| **Consumer Groups** | Redis Streams con `XREADGROUP` + `XAUTOCLAIM` | Entrega confiable + catch-up |

### 1.2 Estructura Modular

```
ws_gateway/
‚îú‚îÄ‚îÄ main.py                    # Orquestador principal + lifespan
‚îú‚îÄ‚îÄ connection_manager.py      # Fachada que compone componentes
‚îú‚îÄ‚îÄ redis_subscriber.py        # Pub/Sub legacy (ephemeral)
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ auth/strategies.py     # Auth pluggable (JWT, Table Token)
‚îÇ   ‚îú‚îÄ‚îÄ connection/            # Heartbeat, Rate Limiter, Index, Locks
‚îÇ   ‚îú‚îÄ‚îÄ endpoints/             # Base classes + handlers espec√≠ficos
‚îÇ   ‚îú‚îÄ‚îÄ events/router.py       # Routing de eventos a conexiones
‚îÇ   ‚îú‚îÄ‚îÄ metrics/               # Prometheus + collector
‚îÇ   ‚îî‚îÄ‚îÄ resilience/            # Circuit Breaker, Retry configs
‚îî‚îÄ‚îÄ core/
    ‚îú‚îÄ‚îÄ connection/            # Lifecycle, Broadcaster, Cleanup
    ‚îî‚îÄ‚îÄ subscriber/            # Stream Consumer + Drop Tracker
```

**Observaci√≥n**: La estructura es excelente y sigue Single Responsibility Principle. Cada componente tiene una responsabilidad clara.

---

## 2. Hallazgos de Seguridad

### üü° **SEC-HIGH-01**: Token Expiration No Verificado en Tabla Token Diner

**Archivo**: `ws_gateway/components/auth/strategies.py` l√≠neas 317-358

```python
class TableTokenAuthStrategy(AuthStrategy, OriginValidationMixin):
    async def revalidate(self, token: str) -> bool:
        """
        Revalidate table token.
        Table tokens don't typically need revalidation during a session
        as they represent physical presence at a table.
        """
        # ‚ùå No verifica expiraci√≥n del token durante sesi√≥n larga
        try:
            verify_table_token(token)
            return True
```

**Problema**: El comentario indica que no hay revalidaci√≥n peri√≥dica. Si un token de mesa expira durante una sesi√≥n larga (ej: 2+ horas de cena), el cliente mantiene la conexi√≥n indefinidamente.

**Impacto**: Bajo-Medio. Los table tokens son de vida corta y solo permiten operaciones limitadas.

**Recomendaci√≥n**: Agregar verificaci√≥n peri√≥dica (cada 30 min) para tokens de mesa largos:
```python
async def _pre_message_hook(self) -> bool:
    if self._should_check_token_expiry():
        if not await self.validate_table_token():
            await self.websocket.close(code=4001, reason="Token expired")
            return False
    return True
```

---

### üü° **SEC-MED-01**: Origin Header Bypass en Development

**Archivo**: `ws_gateway/components/core/constants.py` l√≠neas 300-308

```python
if not origin:
    is_dev = getattr(settings, "environment", "production") == "development"
    if is_dev:
        _logger.warning(
            "WebSocket connection with missing Origin header (allowed in dev mode only)",
        )
        return True  # ‚Üê BYPASS
```

**Problema**: En modo desarrollo, conexiones sin Origin header son permitidas. Un misconfiguration de `environment` podr√≠a exponer esto en producci√≥n.

**Recomendaci√≥n**: Agregar doble verificaci√≥n:
```python
if is_dev and not os.environ.get("PRODUCTION_CHECK"):
```

---

### üü° **SEC-MED-02**: Non-Recoverable Codes No Incluye Rate Limited

**Archivo**: `Dashboard/src/services/websocket.ts` l√≠neas 154-157

```typescript
const NON_RECOVERABLE_CLOSE_CODES = new Set([
  4001, // AUTH_FAILED
  4003, // FORBIDDEN
  // ‚ùå 4029 (RATE_LIMITED) no est√° aqu√≠
])
```

**Problema**: El c√≥digo 4029 (rate limited) no est√° en la lista. Un cliente que hace flood de mensajes ser√° desconectado pero intentar√° reconectar infinitamente.

**Recomendaci√≥n**: Agregar `4029` a la lista o implementar backoff espec√≠fico:
```typescript
const NON_RECOVERABLE_CLOSE_CODES = new Set([
  4001, // AUTH_FAILED
  4003, // FORBIDDEN
  4029, // RATE_LIMITED - don't retry, user is spamming
])
```

---

## 3. Hallazgos de Resiliencia

### ‚úÖ **Patrones Robustos Implementados**

| Mecanismo | Estado | Detalles |
|-----------|--------|----------|
| **Circuit Breaker** | ‚úÖ | 5 failures ‚Üí OPEN, 30s recovery, 3 test calls |
| **Exponential Backoff** | ‚úÖ | 1s-30s con 30% jitter en todos los clientes |
| **Heartbeat Bidireccional** | ‚úÖ | 30s ping, 10s timeout |
| **PEL Recovery** | ‚úÖ | XAUTOCLAIM cada 30 ciclos para mensajes perdidos |
| **NOGROUP Handling** | ‚úÖ | Recreaci√≥n autom√°tica del consumer group |
| **Dead Connection Cleanup** | ‚úÖ | Cada 30s con l√≠mite de 500 conexiones muertas |
| **Visibility Change Listener** | ‚úÖ | Reconexi√≥n tras sleep/tab switch |

### üü° **RES-MED-01**: No Hay Backoff Espec√≠fico para Errores de Red

**Archivo**: `pwaMenu/src/services/websocket.ts` l√≠neas 268-291

```typescript
private scheduleReconnect(): void {
    if (this.reconnectAttempts >= MAX_RECONNECT_ATTEMPTS) {
      wsLogger.error(' Max reconnect attempts reached')
      return  // ‚Üê Se rinde silenciosamente
    }
```

**Problema**: Cuando se alcanza el m√°ximo de intentos, el cliente se rinde sin notificar al usuario.

**Recomendaci√≥n**: Agregar callback `onMaxReconnectReached` como en Dashboard:
```typescript
private onMaxReconnectReached: MaxReconnectCallback | null = null

if (this.reconnectAttempts >= MAX_RECONNECT_ATTEMPTS) {
    this.onMaxReconnectReached?.()
    return
}
```

---

### üü° **RES-MED-02**: Stream Consumer Sin Retry Exponencial

**Archivo**: `ws_gateway/core/subscriber/stream_consumer.py` l√≠neas 156-159

```python
except Exception as e:
    logger.error("Error in stream consumer loop", error=str(e))
    await asyncio.sleep(1)  # ‚Üê Delay fijo
```

**Problema**: Errores gen√©ricos usan delay fijo de 1s. Bajo carga alta, esto podr√≠a causar tight loop.

**Recomendaci√≥n**: Aplicar backoff progresivo:
```python
error_count = 0
# En el loop:
except Exception as e:
    error_count += 1
    delay = min(1 * (2 ** error_count), 30)
    await asyncio.sleep(delay)
```

---

### üü¢ **RES-LOW-01**: DLQ Solo es Logging

**Archivo**: `ws_gateway/core/subscriber/stream_consumer.py` l√≠neas 206-219

```python
if retry_count >= PEL_MAX_RETRIES:
    logger.error(
        "Message exceeded max retries, moving to DLQ",
        msg_id=message_id,
    )
    await redis_pool.xack(...)
    # TODO: In production, store in actual DLQ for manual review
```

**Problema**: Los mensajes que fallan 3 veces solo se loguean. No hay DLQ real.

**Recomendaci√≥n para Producci√≥n**: Implementar DLQ f√≠sico:
```python
await redis_pool.xadd(
    "events:dlq",
    {"original_id": message_id, "data": data_str, "error": str(last_error)}
)
```

---

## 4. Hallazgos de Escalabilidad

### üü° **SCALE-HIGH-01**: Broadcasting Sin Pipelining

**Archivo**: `ws_gateway/core/connection/broadcaster.py` l√≠neas 161-180

```python
for i in range(0, len(connections), self._batch_size):
    batch = connections[i : i + self._batch_size]
    results = await asyncio.gather(
        *[self._send_to_connection(ws, payload) for ws in batch],
        return_exceptions=True,
    )
```

**Problema**: Cada `send_json()` es una operaci√≥n individual. Con 1000 conexiones √ó 50 batches = 20 serial gather calls.

**Impacto**: Latencia O(n/batch_size) para broadcasts grandes.

**Recomendaci√≥n**: Considerar `asyncio.Queue` + worker pool:
```python
async def _broadcast_worker(self, queue: asyncio.Queue):
    while True:
        ws, payload = await queue.get()
        await self._send_to_connection(ws, payload)
        queue.task_done()
```

---

### üü° **SCALE-HIGH-02**: EventRouter Crea Objeto Por Evento

**Archivo**: `ws_gateway/main.py` l√≠neas 152-161

```python
_event_router: EventRouter | None = None

def _get_event_router() -> EventRouter:
    global _event_router
    if _event_router is None:
        _event_router = EventRouter(manager)
    return _event_router
```

**Observaci√≥n**: ‚úÖ Ya est√° optimizado como singleton lazy.

Sin embargo:

**Archivo**: `ws_gateway/components/events/router.py` l√≠neas 196-199

```python
tenant_id = safe_int(event.get("tenant_id"), "tenant_id")
branch_id = safe_int(event.get("branch_id"), "branch_id")
session_id = safe_int(event.get("session_id"), "session_id")
sector_id = safe_int(event.get("sector_id"), "sector_id")
```

**Problema Potencial**: `safe_int()` hace 4 llamadas a logger si hay valores inv√°lidos. En alto throughput (1000 eventos/s con malformed data), esto genera log spam.

**Recomendaci√≥n**: Agregar rate limiting al logging de validaci√≥n:
```python
_last_safe_int_warning = 0

def safe_int(value, field_name: str) -> int | None:
    global _last_safe_int_warning
    # ... existing logic ...
    if time.time() - _last_safe_int_warning > 60:
        logger.warning(...)
        _last_safe_int_warning = time.time()
```

---

### üü° **SCALE-MED-01**: Lock Manager Sin Sharding Din√°mico

**Archivo**: `ws_gateway/components/connection/locks.py`

**Observaci√≥n**: El sistema usa locks por branch/user, lo cual es bueno. Sin embargo:

- MAX_CACHED_LOCKS = 500
- LOCK_CLEANUP_THRESHOLD = 400

**Problema**: Con 500+ branches simult√°neos, se activa cleanup frecuente.

**Recomendaci√≥n para Multi-Tenant Masivo**: Considerar sharding por tenant_id:
```python
def get_branch_lock(self, branch_id: int, tenant_id: int) -> asyncio.Lock:
    shard_key = f"{tenant_id}:{branch_id}"
    # ...
```

---

## 5. Hallazgos Cliente-Side

### ‚úÖ **Consistencia Entre Clientes**

| Feature | Dashboard | pwaWaiter | pwaMenu |
|---------|-----------|-----------|---------|
| Exponential Backoff | ‚úÖ | ‚úÖ | ‚úÖ |
| Jitter (30%) | ‚úÖ | ‚úÖ | ‚úÖ |
| Heartbeat Timeout | ‚úÖ 10s | ‚úÖ 10s | ‚úÖ 10s |
| Visibility Handler | ‚úÖ | ‚úÖ | ‚úÖ |
| Listener Cleanup | ‚úÖ | ‚úÖ | ‚úÖ |
| Max Reconnect (50) | ‚úÖ | ‚ùå (10) | ‚ùå (10) |
| Max Reconnect Callback | ‚úÖ | ‚ùå | ‚ùå |
| Throttled Subscriptions | ‚úÖ | ‚ùå | ‚ùå |

### üü° **CLIENT-MED-01**: Inconsistencia en MAX_RECONNECT_ATTEMPTS

- Dashboard: 50 intentos
- pwaWaiter: 10 intentos
- pwaMenu: 10 intentos

**Recomendaci√≥n**: Unificar a 50 o crear constante compartida.

---

### üü¢ **CLIENT-LOW-01**: pwaWaiter No Tiene onThrottled

**Archivo**: `pwaWaiter/src/services/websocket.ts`

El servicio no implementa `onThrottled()` para eventos de alta frecuencia.

**Impacto**: Si un waiter recibe muchos eventos r√°pidos (ej: m√∫ltiples pedidos simult√°neos), podr√≠a causar re-renders excesivos.

**Recomendaci√≥n**: Agregar `onThrottled()` similar a Dashboard.

---

### üü¢ **CLIENT-LOW-02**: pwaMenu Listeners No Se Limpian al Vaciar

**Archivo**: `pwaMenu/src/services/websocket.ts` l√≠neas 228-237

```typescript
on(eventType: WSEventType | '*', callback: EventCallback): () => void {
    if (!this.listeners.has(eventType)) {
      this.listeners.set(eventType, new Set())
    }
    this.listeners.get(eventType)!.add(callback)
    return () => {
      this.listeners.get(eventType)?.delete(callback)
      // ‚ùå No limpia el Set vac√≠o
    }
  }
```

**Problema**: A diferencia de Dashboard, los Sets vac√≠os no se eliminan del Map.

**Recomendaci√≥n**: Agregar cleanup:
```typescript
return () => {
    const listeners = this.listeners.get(eventType)
    listeners?.delete(callback)
    if (listeners?.size === 0) {
        this.listeners.delete(eventType)
    }
}
```

---

## 6. Recomendaciones de Implementaci√≥n

### Prioridad Alta üî¥

| ID | Hallazgo | Esfuerzo | Impacto |
|----|----------|----------|---------|
| SEC-MED-02 | Agregar 4029 a NON_RECOVERABLE_CLOSE_CODES | 5 min | Previene spam reconnect |
| RES-MED-01 | Agregar onMaxReconnectReached a pwaMenu/pwaWaiter | 15 min | UX en error de conexi√≥n |
| CLIENT-MED-01 | Unificar MAX_RECONNECT_ATTEMPTS | 5 min | Consistencia |

### Prioridad Media üü°

| ID | Hallazgo | Esfuerzo | Impacto |
|----|----------|----------|---------|
| SEC-HIGH-01 | Revalidaci√≥n peri√≥dica de table tokens | 1h | Seguridad de sesiones largas |
| RES-MED-02 | Backoff exponencial en stream consumer errors | 30 min | Estabilidad bajo carga |
| SCALE-HIGH-01 | Worker pool para broadcasting | 2-3h | Performance 1000+ conexiones |
| CLIENT-LOW-01 | Agregar onThrottled a pwaWaiter | 30 min | Performance UI |
| CLIENT-LOW-02 | Cleanup de Sets vac√≠os en pwaMenu | 5 min | Memory leak menor |

### Prioridad Baja üü¢

| ID | Hallazgo | Esfuerzo | Impacto |
|----|----------|----------|---------|
| SEC-MED-01 | Doble verificaci√≥n de environment | 15 min | Seguridad edge case |
| RES-LOW-01 | Implementar DLQ f√≠sico | 2h | Recuperaci√≥n manual |
| SCALE-MED-01 | Sharding de locks por tenant | 3-4h | Multi-tenant masivo |

---

## 7. M√©tricas de Observabilidad Existentes ‚úÖ

El sistema ya expone m√©tricas relevantes:

| Endpoint | Datos |
|----------|-------|
| `/ws/health` | Conexiones totales, estado b√°sico |
| `/ws/health/detailed` | Redis health, subscriber metrics |
| `/ws/metrics` | Prometheus format: broadcast count, failures, rate limits |

**M√©tricas de Circuit Breaker**:
- `state`, `failure_count`, `total_calls`, `rejected_calls`, `state_changes`

**M√©tricas de Rate Limiter**:
- `tracked_connections`, `total_allowed`, `total_rejected`, `evictions`

---

## 8. Conclusi√≥n

El sistema WebSocket del proyecto Integrador es **maduro y bien dise√±ado**:

- ‚úÖ **Arquitectura modular** con composici√≥n de componentes
- ‚úÖ **Autenticaci√≥n robusta** con estrategias pluggables
- ‚úÖ **Resiliencia probada** con circuit breaker, exponential backoff, y PEL recovery
- ‚úÖ **Multi-tenant** con filtrado por tenant_id en todos los broadcasts
- ‚úÖ **Observabilidad** con m√©tricas Prometheus y health checks

**√Åreas de Mejora**:
- Consistencia entre clientes (MAX_RECONNECT, throttling)
- Escalabilidad horizontal (worker pools, lock sharding)
- Seguridad edge cases (table token long sessions)

**Pr√≥ximos Pasos Recomendados**:
1. Implementar fixes de Prioridad Alta (30 min total)
2. Agregar tests de stress para validar comportamiento con 1000+ conexiones
3. Considerar implementaci√≥n de worker pool si se observan latencias en broadcasts

---

*Auditor√≠a generada por Antigravity Assistant*
